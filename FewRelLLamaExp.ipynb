{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4e830a1-0b9d-45c9-9e5d-55274f75c7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import spacy\n",
    "import Utility as util\n",
    "from Utility import REDataset_entities, REModelWithAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0bcf97a-2d80-4699-bb89-1035f9faa511",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fewRel = pd.read_csv('fewRel_entities.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac24e23c-046e-4cd8-84b6-034675b173f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aug_llama = pd.read_csv('aug_llama_entities_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b47cdfb-29ca-4936-baf3-400d6db56a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orignal dataset = 44800 and augumented data = 2783\n"
     ]
    }
   ],
   "source": [
    "print(f'orignal dataset = {len(df_fewRel)} and augumented data = {len(df_aug_llama)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5885395-611d-4662-b0de-9aa3dbbca41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aug_llama = util.sampleData(df_aug_llama,'relation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ddf9770-d34d-4b91-a71d-5a72eb8d8743",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2783"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_aug_llama)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c14a2df6-b434-462a-91a2-aeb49d194aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set = 35840 and test set = 8960\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(df_fewRel, test_size=0.2, random_state=42) # To take test set from orignal data\n",
    "print(f'Train set = {len(train_df)} and test set = {len(test_df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66f0209c-a121-46df-89a2-7ab7ef127da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38623\n"
     ]
    }
   ],
   "source": [
    "df_combined = pd.concat([train_df, df_aug_llama], ignore_index=True) # combined augumented data with orignal FewRel training data\n",
    "print(len(df_combined))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09e572c7-d187-48a2-af80-648f4a855527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode training and test set for relation\n",
    "label_encoder = LabelEncoder()\n",
    "df_combined['relation_id'] = label_encoder.fit_transform(df_combined['relation'])\n",
    "test_df['relation_id'] = label_encoder.fit_transform(test_df['relation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4b908e2-bdb0-4402-a49a-0454d805ff10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")  # Choose the same model as in your model\n",
    "# Check for GPU availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79781e45-f7b8-4ea4-8c81-31f803e5e152",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = 128  \n",
    "train_dataset = util.REDataset_entities(df_combined,tokenizer, max_seq_length)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "test_dataset = util.REDataset_entities(test_df, tokenizer, max_seq_length)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b369f341-6cfc-47e2-8ead-ea97ff6e0ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = REModelWithAttention(tokenizer, num_classes=len(label_encoder.classes_)).to(device)\n",
    "\n",
    "# Define your loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97776a8b-bcb5-40ba-be1b-23dbd3ef9c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss, valid_loss = util.train(model, train_loader, test_loader, criterion, optimizer, device, patience=4, num_epochs=20) # All with entities and empty removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fea71d7b-6de1-4d1a-82ea-42c9a6df3f46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2dfced25-20ef-42b6-816c-3a95c29e9a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20] - Training Loss: 2.1146- Validation Loss: 1.3011\n",
      "Epoch [2/20] - Training Loss: 1.0889- Validation Loss: 1.0722\n",
      "Epoch [3/20] - Training Loss: 0.7658- Validation Loss: 1.0116\n",
      "Epoch [4/20] - Training Loss: 0.5485- Validation Loss: 1.0325\n",
      "Epoch [5/20] - Training Loss: 0.3898- Validation Loss: 1.0706\n",
      "Epoch [6/20] - Training Loss: 0.2780- Validation Loss: 1.1378\n",
      "Epoch [7/20] - Training Loss: 0.2065- Validation Loss: 1.1919\n",
      "Early stopping after 7 epochs without improvement.\n"
     ]
    }
   ],
   "source": [
    "train_loss, valid_loss = util.train(model, train_loader, test_loader, criterion, optimizer, device, patience=4, num_epochs=20) # with entities 3%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d9d4eb85-8815-4a50-a2df-e270b2f22b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7156\n",
      "Precision: 0.7165\n",
      "Recall: 0.7134\n",
      "F1 Score: 0.7118\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model, test_loader,device) # with entities All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2980e6b7-22f5-4070-ab1d-082c13e75844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20] - Training Loss: 2.0879- Validation Loss: 1.3162\n",
      "Epoch [2/20] - Training Loss: 1.0802- Validation Loss: 1.0909\n",
      "Epoch [3/20] - Training Loss: 0.7499- Validation Loss: 1.0562\n",
      "Epoch [4/20] - Training Loss: 0.5295- Validation Loss: 1.0380\n",
      "Epoch [5/20] - Training Loss: 0.3737- Validation Loss: 1.0654\n",
      "Epoch [6/20] - Training Loss: 0.2687- Validation Loss: 1.1337\n",
      "Epoch [7/20] - Training Loss: 0.1962- Validation Loss: 1.2125\n",
      "Epoch [8/20] - Training Loss: 0.1493- Validation Loss: 1.2774\n",
      "Early stopping after 8 epochs without improvement.\n"
     ]
    }
   ],
   "source": [
    "train_loss, valid_loss = util.train(model, train_loader, test_loader, criterion, optimizer, device, patience=4, num_epochs=20) # with entities All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "610fa90f-938e-4e18-83b5-91af43fe07a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7188\n",
      "Precision: 0.7166\n",
      "Recall: 0.7173\n",
      "F1 Score: 0.7124\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model, test_loader,device) # with entities All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4a29e51-9b26-4773-b1ce-89c184ba48e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, data_loader,device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    " \n",
    "    with torch.no_grad():\n",
    "        for input_ids, attention_mask, targets in data_loader:\n",
    "            input_ids, attention_mask, targets = input_ids.to(device), attention_mask.to(device), targets.to(device)\n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            loss = criterion(outputs, targets)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_predictions += (predicted == targets).sum().item()\n",
    "            total_samples += targets.size(0)\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_targets.extend(targets.cpu().numpy())\n",
    "    average_loss = total_loss / len(data_loader)\n",
    "\n",
    "    accuracy = accuracy_score(all_targets, all_predictions)\n",
    "    precision = precision_score(all_targets, all_predictions, average='macro')\n",
    "    recall = recall_score(all_targets, all_predictions, average='macro')\n",
    "    f1 = f1_score(all_targets, all_predictions, average='macro')\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ca284c-3a52-464b-a414-c5277227d7eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fd2d870",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import spacy\n",
    "import Utility as util\n",
    "from Utility import REDataset_entities, REModelWithAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42aec1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fewRel = pd.read_csv('fewRel_entities.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afad8cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aug_llama = pd.read_csv('aug_llama_entities_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d436ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orignal dataset = 44800 and augumented data = 2783\n"
     ]
    }
   ],
   "source": [
    "print(f'orignal dataset = {len(df_fewRel)} and augumented data = {len(df_aug_llama)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75d42e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aug_llama = util.sampleData(df_aug_llama,'relation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d2ec0e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2783"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_aug_llama)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d1a2006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set = 35840 and test set = 8960\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(df_fewRel, test_size=0.2, random_state=42) # To take test set from orignal data\n",
    "print(f'Train set = {len(train_df)} and test set = {len(test_df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3fa210a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38623\n"
     ]
    }
   ],
   "source": [
    "df_combined = pd.concat([train_df, df_aug_llama], ignore_index=True) # combined augumented data with orignal FewRel training data\n",
    "print(len(df_combined))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4974fd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode training and test set for relation\n",
    "label_encoder = LabelEncoder()\n",
    "df_combined['relation_id'] = label_encoder.fit_transform(df_combined['relation'])\n",
    "test_df['relation_id'] = label_encoder.fit_transform(test_df['relation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae5058c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")  # Choose the same model as in your model\n",
    "# Check for GPU availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68a98ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = 128  \n",
    "train_dataset = util.REDataset_entities(df_combined,tokenizer, max_seq_length)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "test_dataset = util.REDataset_entities(test_df, tokenizer, max_seq_length)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13d37939",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = REModelWithAttention(tokenizer, num_classes=len(label_encoder.classes_)).to(device)\n",
    "\n",
    "# Define your loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d1a199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20] - Training Loss: 2.1503- Validation Loss: 1.3061\n",
      "Epoch [2/20] - Training Loss: 1.0838- Validation Loss: 1.0952\n",
      "Epoch [3/20] - Training Loss: 0.7501- Validation Loss: 1.0367\n",
      "Epoch [4/20] - Training Loss: 0.5297- Validation Loss: 1.0666\n",
      "Epoch [5/20] - Training Loss: 0.3756- Validation Loss: 1.1117\n",
      "Epoch [6/20] - Training Loss: 0.2692- Validation Loss: 1.1699\n",
      "Epoch [7/20] - Training Loss: 0.1919- Validation Loss: 1.2417\n",
      "Early stopping after 7 epochs without improvement.\n"
     ]
    }
   ],
   "source": [
    "train_loss, valid_loss = util.train(model, train_loader, test_loader, criterion, optimizer, device, patience=4, num_epochs=20) # All with entities also empty removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c1da1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7100\n",
      "Precision: 0.7153\n",
      "Recall: 0.7082\n",
      "F1 Score: 0.7086\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model, test_loader,device) # All with entities also empty removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42bfabdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20] - Training Loss: 2.1146- Validation Loss: 1.3011\n",
      "Epoch [2/20] - Training Loss: 1.0889- Validation Loss: 1.0722\n",
      "Epoch [3/20] - Training Loss: 0.7658- Validation Loss: 1.0116\n",
      "Epoch [4/20] - Training Loss: 0.5485- Validation Loss: 1.0325\n",
      "Epoch [5/20] - Training Loss: 0.3898- Validation Loss: 1.0706\n",
      "Epoch [6/20] - Training Loss: 0.2780- Validation Loss: 1.1378\n",
      "Epoch [7/20] - Training Loss: 0.2065- Validation Loss: 1.1919\n",
      "Early stopping after 7 epochs without improvement.\n"
     ]
    }
   ],
   "source": [
    "train_loss, valid_loss = util.train(model, train_loader, test_loader, criterion, optimizer, device, patience=4, num_epochs=20) # with entities 3%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ad0cfdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7156\n",
      "Precision: 0.7165\n",
      "Recall: 0.7134\n",
      "F1 Score: 0.7118\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model, test_loader,device) #  with entities 3%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d5744a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20] - Training Loss: 2.0879- Validation Loss: 1.3162\n",
      "Epoch [2/20] - Training Loss: 1.0802- Validation Loss: 1.0909\n",
      "Epoch [3/20] - Training Loss: 0.7499- Validation Loss: 1.0562\n",
      "Epoch [4/20] - Training Loss: 0.5295- Validation Loss: 1.0380\n",
      "Epoch [5/20] - Training Loss: 0.3737- Validation Loss: 1.0654\n",
      "Epoch [6/20] - Training Loss: 0.2687- Validation Loss: 1.1337\n",
      "Epoch [7/20] - Training Loss: 0.1962- Validation Loss: 1.2125\n",
      "Epoch [8/20] - Training Loss: 0.1493- Validation Loss: 1.2774\n",
      "Early stopping after 8 epochs without improvement.\n"
     ]
    }
   ],
   "source": [
    "train_loss, valid_loss = util.train(model, train_loader, test_loader, criterion, optimizer, device, patience=4, num_epochs=20) # with entities All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2109b986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7188\n",
      "Precision: 0.7166\n",
      "Recall: 0.7173\n",
      "F1 Score: 0.7124\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model, test_loader,device) # with entities All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "309e3edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, data_loader,device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    " \n",
    "    with torch.no_grad():\n",
    "        for input_ids, attention_mask, targets in data_loader:\n",
    "            input_ids, attention_mask, targets = input_ids.to(device), attention_mask.to(device), targets.to(device)\n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            loss = criterion(outputs, targets)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_predictions += (predicted == targets).sum().item()\n",
    "            total_samples += targets.size(0)\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_targets.extend(targets.cpu().numpy())\n",
    "    average_loss = total_loss / len(data_loader)\n",
    "\n",
    "    accuracy = accuracy_score(all_targets, all_predictions)\n",
    "    precision = precision_score(all_targets, all_predictions, average='macro')\n",
    "    recall = recall_score(all_targets, all_predictions, average='macro')\n",
    "    f1 = f1_score(all_targets, all_predictions, average='macro')\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8638482",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
